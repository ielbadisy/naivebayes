---
title: "Specialized Naive Bayes"
---

The `naivebayes` package provides a range of functions that implement specialised versions of the Na&iuml;ve Bayes and in this short vignette their basic usage is demonstrated.


## Bernoulli Naive Bayes

### Simulate data

```{r data}
library(naivebayes)
cols <- 10 ; rows <- 100 ; probs <- c("0" = 0.4, "1" = 0.1)
M <- matrix(sample(0:1, rows * cols,  TRUE, probs), nrow = rows, ncol = cols)
y <- factor(sample(paste0("class", LETTERS[1:2]), rows, TRUE, prob = c(0.3,0.7)))
colnames(M) <- paste0("V", seq_len(ncol(M)))
laplace <- 0.5
```

### Train the Bernoulli Naive Bayes model

```{r}
# M has to be a matrix
bnb <- bernoulli_naive_bayes(x = M, y = y, laplace = laplace)
summary(bnb)
head(predict(bnb, newdata = M, type = "prob")) 

# Equivalently
head(bnb %prob% M)

# Visualise marginal distributions
plot(bnb, which = "V1", prob = "marginal")

# Obtain model coefficients
coef(bnb)
```


###  Equivalent calculation with naive_bayes function

```{r}
# It is made sure that the columns are factors with the 0-1 levels)
df <- as.data.frame(lapply(as.data.frame(M), factor, levels = c(0,1)))
# sapply(df, class)
nb <- naive_bayes(df, y, laplace = laplace)
head(nb %prob% df)

# Visualise marginal distributions
plot(nb, which = "V1", prob = "marginal")
```

## Multinomial Naive Bayes


### Simulate data

```{r}
cols <- 10 ; rows <- 100
M <- matrix(sample(0:5, rows * cols,  TRUE), nrow = rows, ncol = cols)
y <- factor(sample(paste0("class", LETTERS[1:2]), rows, TRUE, prob = c(0.3,0.7)))
colnames(M) <- paste0("V", seq_len(ncol(M)))
laplace <- 1

```

### Train the Multinomial Naive Bayes

```{r}
mnb <- multinomial_naive_bayes(x = M, y = y, laplace = laplace)
summary(mnb)

# Classification
head(mnb %class% M)

# Posterior probabilities
head(mnb %prob% M)

# Parameter estimates
coef(mnb)
```

## Poisson Naive Bayes

### Simulate data

```{r}
cols <- 10 ; rows <- 100
M <- matrix(rpois(rows * cols, lambda = 3), nrow = rows, ncol = cols)
# is.integer(M) # [1] TRUE
y <- factor(sample(paste0("class", LETTERS[1:2]), rows, TRUE))
colnames(M) <- paste0("V", seq_len(ncol(M)))
```

### Train the Poisson Naive Bayes

```{r}
laplace <- 0
pnb <- poisson_naive_bayes(x = M, y = y, laplace = laplace)
summary(pnb)
head(predict(pnb, newdata = M, type = "prob"))

# Visualise marginal distributions
plot(pnb, which = "V1", prob = "marginal")

# Obtain model coefficients
coef(pnb)

```

###  Equivalent calculation with naive_bayes function

```{r}
nb2 <- naive_bayes(M, y, usepoisson = TRUE, laplace = laplace)
head(predict(nb2, type = "prob"))
# Visualise marginal distributions
plot(nb2, which = "V1", prob = "marginal")
```



## Gaussian Naive Bayes

### Data

```{r}
data(iris)
y <- iris[[5]]
M <- as.matrix(iris[-5])
```

### Train the Gaussian Naive Bayes

```{r}
gnb <- gaussian_naive_bayes(x = M, y = y)
summary(gnb)

# Visualise class conditional distributions
plot(gnb, which = "Sepal.Width", prob = "conditional")

# Obtain parameter estimates
coef(gnb)

coef(gnb)[c(TRUE,FALSE)] # Only means
```

###  Equivalent calculation with general naive_bayes function.

```{r}
nb3 <- naive_bayes(M, y)
summary(nb3)
```


## Non-Parametric Naive Bayes

### Data

```{r}
data(iris)
y <- iris[[5]]
M <- as.matrix(iris[-5])
```

### Train the Non-Parametric Naive Bayes

```{r}
nnb <- nonparametric_naive_bayes(x = M, y = y)
plot(nnb, 1, prob = "conditional")
```


###  Equivalent calculation with general naive_bayes function:

```{r}
nb4 <- naive_bayes(M, y, usekernel = TRUE)
plot(nb4, 1, prob = "conditional")
```
